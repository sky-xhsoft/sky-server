package cloud

import (
	"context"
	"crypto/md5"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"math"
	"os"
	"path/filepath"
	"sort"
	"time"

	"github.com/google/uuid"
	"github.com/sky-xhsoft/sky-server/internal/model/entity"
	"github.com/sky-xhsoft/sky-server/internal/pkg/errors"
	"github.com/sky-xhsoft/sky-server/internal/pkg/logger"
	"github.com/sky-xhsoft/sky-server/internal/pkg/storage"
	"go.uber.org/zap"
	"gorm.io/gorm"
)

// MultipartUploadService 分片上传服务接口
type MultipartUploadService interface {
	// InitUpload 初始化上传会话
	InitUpload(ctx context.Context, req *InitUploadRequest, userID uint) (*UploadSessionInfo, error)

	// UploadChunk 上传单个分片
	UploadChunk(ctx context.Context, req *UploadChunkRequest, userID uint) error

	// GetUploadStatus 获取上传状态
	GetUploadStatus(ctx context.Context, sessionID uint, userID uint) (*UploadStatus, error)

	// CompleteUpload 完成上传（合并分片）
	CompleteUpload(ctx context.Context, sessionID uint, userID uint) (*entity.CloudFile, error)

	// AbortUpload 取消上传
	AbortUpload(ctx context.Context, sessionID uint, userID uint) error

	// ResumeUpload 恢复上传（断点续传）
	ResumeUpload(ctx context.Context, fileMD5 string, userID uint) (*UploadSessionInfo, error)

	// CleanupExpiredSessions 清理过期会话
	CleanupExpiredSessions(ctx context.Context) error
}

// InitUploadRequest 初始化上传请求
type InitUploadRequest struct {
	FileName    string `json:"fileName" binding:"required"`
	FileSize    int64  `json:"fileSize" binding:"required"`
	FileMD5     string `json:"fileMd5" binding:"required"`
	FileType    string `json:"fileType"`
	ChunkSize   int    `json:"chunkSize"`
	FolderID    *uint  `json:"folderId"`
	StorageType string `json:"storageType"` // local 或 oss
}

// UploadChunkRequest 上传分片请求
type UploadChunkRequest struct {
	SessionID  uint   `json:"sessionId" binding:"required"`
	ChunkIndex int    `json:"chunkIndex" binding:"required"`
	ChunkData  []byte `json:"-"` // 二进制数据（从 multipart form 获取）
	ChunkMD5   string `json:"chunkMd5" binding:"required"`
}

// UploadSessionInfo 上传会话信息
type UploadSessionInfo struct {
	SessionID      uint   `json:"sessionId"`
	FileID         string `json:"fileId"`
	FileName       string `json:"fileName"`
	FileSize       int64  `json:"fileSize"`
	ChunkSize      int    `json:"chunkSize"`
	TotalChunks    int    `json:"totalChunks"`
	UploadedChunks []int  `json:"uploadedChunks"`
	Status         string `json:"status"`
	ExpireTime     string `json:"expireTime"`
}

// UploadStatus 上传状态
type UploadStatus struct {
	SessionID      uint    `json:"sessionId"`
	FileID         string  `json:"fileId"`
	FileName       string  `json:"fileName"`
	FileSize       int64   `json:"fileSize"`
	TotalChunks    int     `json:"totalChunks"`
	UploadedChunks []int   `json:"uploadedChunks"`
	Status         string  `json:"status"`
	Progress       float64 `json:"progress"`
	ExpireTime     string  `json:"expireTime"`
}

// multipartUploadService 分片上传服务实现
type multipartUploadService struct {
	db                 *gorm.DB
	storage            storage.Storage
	cloudService       Service
	defaultChunkSize   int // 默认分片大小（字节）
	sessionExpireHours int // 会话过期时间（小时）
}

// NewMultipartUploadService 创建分片上传服务
func NewMultipartUploadService(db *gorm.DB, storage storage.Storage, cloudService Service, defaultChunkSize int, sessionExpireHours int) MultipartUploadService {
	// 设置默认值
	if defaultChunkSize <= 0 {
		defaultChunkSize = 5 * 1024 * 1024 // 默认 5MB
	}
	if sessionExpireHours <= 0 {
		sessionExpireHours = 24 // 默认 24 小时
	}

	return &multipartUploadService{
		db:                 db,
		storage:            storage,
		cloudService:       cloudService,
		defaultChunkSize:   defaultChunkSize,
		sessionExpireHours: sessionExpireHours,
	}
}

// InitUpload 初始化上传会话
func (s *multipartUploadService) InitUpload(ctx context.Context, req *InitUploadRequest, userID uint) (*UploadSessionInfo, error) {
	logger.Info("初始化分片上传",
		zap.String("fileName", req.FileName),
		zap.Int64("fileSize", req.FileSize),
		zap.String("fileMD5", req.FileMD5),
		zap.Uint("userID", userID))

	// 1. 检查配额
	if err := s.cloudService.CheckQuota(ctx, userID, req.FileSize); err != nil {
		return nil, err
	}

	// 2. 检查是否存在未完成的会话（断点续传）
	var existingSession entity.CloudUploadSession
	err := s.db.WithContext(ctx).
		Where("FILE_ID = ? AND USER_ID = ? AND STATUS IN (?, ?) AND IS_ACTIVE = ?",
			req.FileMD5, userID, "uploading", "paused", "Y").
		First(&existingSession).Error

	if err == nil {
		// 存在未完成的会话,返回已上传的分片信息
		logger.Info("找到现有上传会话,支持断点续传",
			zap.Uint("sessionID", existingSession.ID),
			zap.String("status", existingSession.Status))

		// 延长会话过期时间(重要:避免用户继续上传时会话已过期)
		newExpireTime := time.Now().Add(time.Duration(s.sessionExpireHours) * time.Hour)
		if err := s.db.WithContext(ctx).Model(&entity.CloudUploadSession{}).
			Where("ID = ?", existingSession.ID).
			Updates(map[string]interface{}{
				"EXPIRE_TIME": newExpireTime,
				"STATUS":      "uploading", // 确保状态为 uploading
				"UPDATE_BY":   fmt.Sprintf("user_%d", userID),
				"UPDATE_TIME": time.Now(),
			}).Error; err != nil {
			logger.Error("更新会话过期时间失败", zap.Error(err))
			// 不返回错误,继续返回会话信息
		}

		var uploadedChunks []int
		if existingSession.UploadedChunks != "" {
			json.Unmarshal([]byte(existingSession.UploadedChunks), &uploadedChunks)
		}

		return &UploadSessionInfo{
			SessionID:      existingSession.ID,
			FileID:         existingSession.FileID,
			FileName:       existingSession.FileName,
			FileSize:       existingSession.FileSize,
			ChunkSize:      existingSession.ChunkSize,
			TotalChunks:    existingSession.TotalChunks,
			UploadedChunks: uploadedChunks,
			Status:         "uploading", // 返回最新状态
			ExpireTime:     newExpireTime.Format(time.RFC3339),
		}, nil
	}
	// 3. 设置默认分片大小（使用配置值）
	chunkSize := req.ChunkSize
	if chunkSize == 0 {
		chunkSize = s.defaultChunkSize
	}

	// 4. 计算总分片数
	totalChunks := int(math.Ceil(float64(req.FileSize) / float64(chunkSize)))

	// 5. 设置存储类型
	storageType := req.StorageType
	if storageType == "" {
		storageType = "local"
	}

	// 6. 创建新的上传会话（使用配置的过期时间）
	expireTime := time.Now().Add(time.Duration(s.sessionExpireHours) * time.Hour)

	session := &entity.CloudUploadSession{
		BaseModel: entity.BaseModel{
			CreateBy: fmt.Sprintf("user_%d", userID),
			UpdateBy: fmt.Sprintf("user_%d", userID),
			IsActive: "Y",
		},
		FileID:         req.FileMD5,
		UserID:         userID,
		FileName:       req.FileName,
		FileSize:       req.FileSize,
		FileType:       req.FileType,
		FolderID:       req.FolderID,
		ChunkSize:      chunkSize,
		TotalChunks:    totalChunks,
		UploadedChunks: "[]",
		Status:         "uploading",
		StorageType:    storageType,
		StoragePath:    fmt.Sprintf("cloud/temp/%d/%s", userID, req.FileMD5),
		ExpireTime:     &expireTime,
	}

	if err := s.db.WithContext(ctx).Create(session).Error; err != nil {
		return nil, errors.Wrap(errors.ErrDatabase, "创建上传会话失败", err)
	}

	logger.Info("创建上传会话成功",
		zap.Uint("sessionID", session.ID),
		zap.Int("totalChunks", totalChunks))

	return &UploadSessionInfo{
		SessionID:      session.ID,
		FileID:         session.FileID,
		FileName:       session.FileName,
		FileSize:       session.FileSize,
		ChunkSize:      session.ChunkSize,
		TotalChunks:    totalChunks,
		UploadedChunks: []int{},
		Status:         "uploading",
		ExpireTime:     expireTime.Format(time.RFC3339),
	}, nil
}

// UploadChunk 上传单个分片
func (s *multipartUploadService) UploadChunk(ctx context.Context, req *UploadChunkRequest, userID uint) error {
	logger.Debug("上传分片",
		zap.Uint("sessionID", req.SessionID),
		zap.Int("chunkIndex", req.ChunkIndex),
		zap.Int("chunkSize", len(req.ChunkData)))

	// 1. 获取上传会话
	var session entity.CloudUploadSession
	if err := s.db.WithContext(ctx).
		Where("ID = ? AND USER_ID = ? AND IS_ACTIVE = ?", req.SessionID, userID, "Y").
		First(&session).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			return errors.New(errors.ErrResourceNotFound, "上传会话不存在")
		}
		return errors.Wrap(errors.ErrDatabase, "查询上传会话失败", err)
	}

	// 2. 检查会话状态
	if session.Status != "uploading" && session.Status != "paused" {
		return errors.New(errors.ErrInvalidParam, fmt.Sprintf("上传会话状态无效: %s", session.Status))
	}

	// 3. 检查会话是否过期
	if session.ExpireTime.Before(time.Now()) {
		return errors.New(errors.ErrInvalidParam, "上传会话已过期")
	}

	// 4. 检查分片索引是否有效
	if req.ChunkIndex < 0 || req.ChunkIndex >= session.TotalChunks {
		return errors.New(errors.ErrInvalidParam, fmt.Sprintf("分片索引无效: %d", req.ChunkIndex))
	}

	// 5. 检查分片是否已上传
	var chunkRecord entity.CloudChunkRecord
	err := s.db.WithContext(ctx).
		Where("SESSION_ID = ? AND CHUNK_INDEX = ?", session.ID, req.ChunkIndex).
		First(&chunkRecord).Error

	if err == nil && chunkRecord.Uploaded {
		logger.Debug("分片已上传，跳过", zap.Int("chunkIndex", req.ChunkIndex))
		return nil // 分片已上传，跳过
	}

	// 6. 验证分片MD5
	actualMD5 := calculateMD5(req.ChunkData)
	if actualMD5 != req.ChunkMD5 {
		logger.Error("分片MD5校验失败",
			zap.Int("chunkIndex", req.ChunkIndex),
			zap.String("expected", req.ChunkMD5),
			zap.String("actual", actualMD5))
		return errors.New(errors.ErrInvalidParam, "分片MD5校验失败")
	}

	// 7. 保存分片到临时目录
	chunkPath := fmt.Sprintf("%s/chunk_%d", session.StoragePath, req.ChunkIndex)

	// 创建 Reader
	chunkReader := &chunkReader{data: req.ChunkData}

	if _, err := s.storage.Upload(ctx, chunkPath, chunkReader, "application/octet-stream"); err != nil {
		logger.Error("保存分片失败",
			zap.Int("chunkIndex", req.ChunkIndex),
			zap.Error(err))
		return errors.Wrap(errors.ErrInternal, "保存分片失败", err)
	}

	// 8. 更新或创建分片记录
	now := time.Now()
	if err == gorm.ErrRecordNotFound {
		// 创建新记录
		chunkRecord = entity.CloudChunkRecord{
			SessionID:  session.ID,
			ChunkIndex: req.ChunkIndex,
			ChunkSize:  len(req.ChunkData),
			ChunkMD5:   req.ChunkMD5,
			ChunkPath:  chunkPath,
			Uploaded:   true,
			UploadTime: &now,
			RetryCount: 0,
		}

		if err := s.db.WithContext(ctx).Create(&chunkRecord).Error; err != nil {
			return errors.Wrap(errors.ErrDatabase, "创建分片记录失败", err)
		}
	} else {
		// 更新现有记录
		if err := s.db.WithContext(ctx).Model(&chunkRecord).Updates(map[string]interface{}{
			"UPLOADED":    true,
			"UPLOAD_TIME": now,
			"RETRY_COUNT": gorm.Expr("RETRY_COUNT + 1"),
		}).Error; err != nil {
			return errors.Wrap(errors.ErrDatabase, "更新分片记录失败", err)
		}
	}

	// 9. 更新上传会话的已上传分片列表
	var uploadedChunks []int
	if session.UploadedChunks != "" {
		json.Unmarshal([]byte(session.UploadedChunks), &uploadedChunks)
	}

	// 检查是否已存在
	exists := false
	for _, idx := range uploadedChunks {
		if idx == req.ChunkIndex {
			exists = true
			break
		}
	}

	if !exists {
		uploadedChunks = append(uploadedChunks, req.ChunkIndex)
		sort.Ints(uploadedChunks)

		uploadedChunksJSON, _ := json.Marshal(uploadedChunks)
		if err := s.db.WithContext(ctx).Model(&entity.CloudUploadSession{}).
			Where("ID = ?", session.ID).
			Update("UPLOADED_CHUNKS", string(uploadedChunksJSON)).Error; err != nil {
			return errors.Wrap(errors.ErrDatabase, "更新会话状态失败", err)
		}
	}

	logger.Debug("分片上传成功",
		zap.Int("chunkIndex", req.ChunkIndex),
		zap.Int("uploaded", len(uploadedChunks)),
		zap.Int("total", session.TotalChunks))

	return nil
}

// GetUploadStatus 获取上传状态
func (s *multipartUploadService) GetUploadStatus(ctx context.Context, sessionID uint, userID uint) (*UploadStatus, error) {
	var session entity.CloudUploadSession
	if err := s.db.WithContext(ctx).
		Where("ID = ? AND USER_ID = ? AND IS_ACTIVE = ?", sessionID, userID, "Y").
		First(&session).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			return nil, errors.New(errors.ErrResourceNotFound, "上传会话不存在")
		}
		return nil, errors.Wrap(errors.ErrDatabase, "查询上传会话失败", err)
	}

	var uploadedChunks []int
	if session.UploadedChunks != "" {
		json.Unmarshal([]byte(session.UploadedChunks), &uploadedChunks)
	}

	progress := float64(len(uploadedChunks)) / float64(session.TotalChunks)

	return &UploadStatus{
		SessionID:      session.ID,
		FileID:         session.FileID,
		FileName:       session.FileName,
		FileSize:       session.FileSize,
		TotalChunks:    session.TotalChunks,
		UploadedChunks: uploadedChunks,
		Status:         session.Status,
		Progress:       progress,
		ExpireTime:     session.ExpireTime.Format(time.RFC3339),
	}, nil
}

// CompleteUpload 完成上传（合并分片）
// 此方法会根据文件大小和分片数量自动选择最优的合并策略：
// - 小文件或少量分片：使用临时文件合并（稳定可靠）
// - 大文件且多分片：使用流式合并（高性能、低内存）
func (s *multipartUploadService) CompleteUpload(ctx context.Context, sessionID uint, userID uint) (*entity.CloudFile, error) {
	logger.Info("完成分片上传", zap.Uint("sessionID", sessionID), zap.Uint("userID", userID))

	// 1. 获取上传会话
	var session entity.CloudUploadSession
	if err := s.db.WithContext(ctx).
		Where("ID = ? AND USER_ID = ? AND IS_ACTIVE = ?", sessionID, userID, "Y").
		First(&session).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			return nil, errors.New(errors.ErrResourceNotFound, "上传会话不存在")
		}
		return nil, errors.Wrap(errors.ErrDatabase, "查询上传会话失败", err)
	}

	// 2. 检查所有分片是否已上传
	var uploadedChunks []int
	if session.UploadedChunks != "" {
		json.Unmarshal([]byte(session.UploadedChunks), &uploadedChunks)
	}

	if len(uploadedChunks) != session.TotalChunks {
		return nil, errors.New(errors.ErrInvalidParam,
			fmt.Sprintf("分片未完全上传：已上传 %d/%d", len(uploadedChunks), session.TotalChunks))
	}

	// 2.5 自动选择合并策略：大文件且多分片使用流式合并
	const (
		streamingChunkThreshold = 10              // 分片数量阈值
		streamingFileSizeThreshold = 50 * 1024 * 1024 // 50MB 文件大小阈值
	)

	// 判断是否使用流式合并优化
	if session.TotalChunks > streamingChunkThreshold && session.FileSize > streamingFileSizeThreshold {
		logger.Info("使用流式合并优化",
			zap.Int("totalChunks", session.TotalChunks),
			zap.Int64("fileSize", session.FileSize))
		return s.completeUploadOptimized(ctx, &session, userID)
	}

	// 3. 检查是否已存在相同MD5的文件（秒传）
	var existingFile entity.CloudFile
	err := s.db.WithContext(ctx).
		Where("MD5 = ? AND OWNER_ID = ? AND IS_ACTIVE = ?", session.FileID, userID, "Y").
		First(&existingFile).Error

	if err == nil {
		// 文件已存在，直接创建新记录（秒传）
		logger.Info("检测到相同文件，使用秒传", zap.String("md5", session.FileID))

		newFile := &entity.CloudFile{
			BaseModel: entity.BaseModel{
				CreateBy: fmt.Sprintf("user_%d", userID),
				UpdateBy: fmt.Sprintf("user_%d", userID),
				IsActive: "Y",
			},
			FileName:    session.FileName,
			FolderID:    session.FolderID,
			StoragePath: existingFile.StoragePath, // 共享存储路径
			FileSize:    session.FileSize,
			FileType:    session.FileType,
			FileExt:     filepath.Ext(session.FileName),
			MD5:         session.FileID,
			OwnerID:     userID,
			StorageType: session.StorageType,
			AccessURL:   existingFile.AccessURL,
		}

		if err := s.db.WithContext(ctx).Create(newFile).Error; err != nil {
			return nil, errors.Wrap(errors.ErrDatabase, "创建文件记录失败（秒传）", err)
		}

		// 更新会话状态
		s.db.WithContext(ctx).Model(&entity.CloudUploadSession{}).
			Where("ID = ?", session.ID).
			Update("STATUS", "completed")

		// 异步清理临时文件
		go s.cleanupChunks(context.Background(), session.ID, session.StoragePath)

		// 更新配额（只增加文件计数，不增加空间使用）
		s.cloudService.UpdateQuota(ctx, userID, 0, 1)

		return newFile, nil
	}

	// 4. 合并分片到最终文件
	finalPath := fmt.Sprintf("cloud/%d/%s/%s%s",
		userID,
		time.Now().Format("2006/01/02"),
		uuid.New().String(),
		filepath.Ext(session.FileName))

	// 使用临时文件合并
	tempMergedFile := filepath.Join(os.TempDir(), fmt.Sprintf("merge_%d.tmp", sessionID))
	mergedFile, err := os.Create(tempMergedFile)
	if err != nil {
		return nil, errors.Wrap(errors.ErrInternal, "创建合并文件失败", err)
	}
	defer func() {
		mergedFile.Close()
		os.Remove(tempMergedFile)
	}()

	// 按顺序合并所有分片
	logger.Info("开始合并分片", zap.Int("totalChunks", session.TotalChunks))

	for i := 0; i < session.TotalChunks; i++ {
		chunkPath := fmt.Sprintf("%s/chunk_%d", session.StoragePath, i)

		// 读取分片
		chunkReader, err := s.storage.Download(ctx, chunkPath)
		if err != nil {
			return nil, errors.Wrap(errors.ErrInternal, fmt.Sprintf("读取分片 %d 失败", i), err)
		}

		// 写入合并文件
		written, err := io.Copy(mergedFile, chunkReader)
		chunkReader.Close()

		if err != nil {
			return nil, errors.Wrap(errors.ErrInternal, fmt.Sprintf("合并分片 %d 失败", i), err)
		}

		logger.Debug("合并分片", zap.Int("chunkIndex", i), zap.Int64("written", written))
	}

	// 5. 验证文件完整性（MD5）
	mergedFile.Seek(0, io.SeekStart)
	actualMD5, err := calculateFileMD5(mergedFile)
	if err != nil {
		return nil, errors.Wrap(errors.ErrInternal, "计算文件MD5失败", err)
	}

	if actualMD5 != session.FileID {
		logger.Error("文件MD5校验失败",
			zap.String("expected", session.FileID),
			zap.String("actual", actualMD5))
		return nil, errors.New(errors.ErrInvalidParam, "文件MD5校验失败")
	}

	logger.Info("文件MD5校验成功", zap.String("md5", actualMD5))

	// 6. 上传最终文件到存储
	mergedFile.Seek(0, io.SeekStart)
	accessURL, err := s.storage.Upload(ctx, finalPath, mergedFile, session.FileType)
	if err != nil {
		return nil, errors.Wrap(errors.ErrInternal, "上传最终文件失败", err)
	}

	// 7. 创建文件记录
	file := &entity.CloudFile{
		BaseModel: entity.BaseModel{
			CreateBy: fmt.Sprintf("user_%d", userID),
			UpdateBy: fmt.Sprintf("user_%d", userID),
			IsActive: "Y",
		},
		FileName:    session.FileName,
		FolderID:    session.FolderID,
		StoragePath: finalPath,
		FileSize:    session.FileSize,
		FileType:    session.FileType,
		FileExt:     filepath.Ext(session.FileName),
		MD5:         session.FileID,
		OwnerID:     userID,
		StorageType: session.StorageType,
		AccessURL:   accessURL,
	}

	if err := s.db.WithContext(ctx).Create(file).Error; err != nil {
		// 删除已上传的文件
		s.storage.Delete(ctx, finalPath)
		return nil, errors.Wrap(errors.ErrDatabase, "创建文件记录失败", err)
	}

	// 8. 更新配额
	s.cloudService.UpdateQuota(ctx, userID, session.FileSize, 1)

	// 9. 更新会话状态为已完成
	s.db.WithContext(ctx).Model(&entity.CloudUploadSession{}).
		Where("ID = ?", session.ID).
		Update("STATUS", "completed")

	// 10. 异步清理临时文件
	go s.cleanupChunks(context.Background(), session.ID, session.StoragePath)

	logger.Info("文件上传完成",
		zap.Uint("fileID", file.ID),
		zap.String("fileName", file.FileName),
		zap.Int64("fileSize", file.FileSize))

	return file, nil
}

// AbortUpload 取消上传
func (s *multipartUploadService) AbortUpload(ctx context.Context, sessionID uint, userID uint) error {
	logger.Info("取消上传", zap.Uint("sessionID", sessionID), zap.Uint("userID", userID))

	// 1. 获取上传会话
	var session entity.CloudUploadSession
	if err := s.db.WithContext(ctx).
		Where("ID = ? AND USER_ID = ? AND IS_ACTIVE = ?", sessionID, userID, "Y").
		First(&session).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			return errors.New(errors.ErrResourceNotFound, "上传会话不存在")
		}
		return errors.Wrap(errors.ErrDatabase, "查询上传会话失败", err)
	}

	// 2. 更新会话状态
	if err := s.db.WithContext(ctx).Model(&entity.CloudUploadSession{}).
		Where("ID = ?", sessionID).
		Updates(map[string]interface{}{
			"STATUS":      "failed",
			"IS_ACTIVE":   "N",
			"UPDATE_BY":   fmt.Sprintf("user_%d", userID),
			"UPDATE_TIME": time.Now(),
		}).Error; err != nil {
		return errors.Wrap(errors.ErrDatabase, "更新会话状态失败", err)
	}

	// 3. 异步清理临时文件
	go s.cleanupChunks(context.Background(), session.ID, session.StoragePath)

	return nil
}

// ResumeUpload 恢复上传（断点续传）
func (s *multipartUploadService) ResumeUpload(ctx context.Context, fileMD5 string, userID uint) (*UploadSessionInfo, error) {
	logger.Info("恢复上传（断点续传）", zap.String("fileMD5", fileMD5), zap.Uint("userID", userID))

	// 查找未完成的会话
	var session entity.CloudUploadSession
	if err := s.db.WithContext(ctx).
		Where("FILE_ID = ? AND USER_ID = ? AND STATUS IN (?, ?) AND IS_ACTIVE = ?",
			fileMD5, userID, "uploading", "paused", "Y").
		First(&session).Error; err != nil {
		if err == gorm.ErrRecordNotFound {
			return nil, errors.New(errors.ErrResourceNotFound, "未找到可恢复的上传会话")
		}
		return nil, errors.Wrap(errors.ErrDatabase, "查询上传会话失败", err)
	}

	// 检查会话是否过期
	if session.ExpireTime.Before(time.Now()) {
		return nil, errors.New(errors.ErrInvalidParam, "上传会话已过期")
	}

	// 获取已上传的分片列表
	var uploadedChunks []int
	if session.UploadedChunks != "" {
		json.Unmarshal([]byte(session.UploadedChunks), &uploadedChunks)
	}

	// 更新会话状态为 uploading 并延长过期时间
	newExpireTime := time.Now().Add(time.Duration(s.sessionExpireHours) * time.Hour)
	s.db.WithContext(ctx).Model(&entity.CloudUploadSession{}).
		Where("ID = ?", session.ID).
		Updates(map[string]interface{}{
			"STATUS":      "uploading",
			"EXPIRE_TIME": newExpireTime,
			"UPDATE_BY":   fmt.Sprintf("user_%d", userID),
			"UPDATE_TIME": time.Now(),
		})

	return &UploadSessionInfo{
		SessionID:      session.ID,
		FileID:         session.FileID,
		FileName:       session.FileName,
		FileSize:       session.FileSize,
		ChunkSize:      session.ChunkSize,
		TotalChunks:    session.TotalChunks,
		UploadedChunks: uploadedChunks,
		Status:         "uploading",
		ExpireTime:     newExpireTime.Format(time.RFC3339),
	}, nil
}

// CleanupExpiredSessions 清理过期会话
func (s *multipartUploadService) CleanupExpiredSessions(ctx context.Context) error {
	logger.Info("开始清理过期会话")

	// 查询过期的会话
	var sessions []entity.CloudUploadSession
	if err := s.db.WithContext(ctx).
		Where("EXPIRE_TIME < ? AND STATUS IN (?, ?, ?) AND IS_ACTIVE = ?",
			time.Now(), "uploading", "paused", "failed", "Y").
		Find(&sessions).Error; err != nil {
		return errors.Wrap(errors.ErrDatabase, "查询过期会话失败", err)
	}

	logger.Info("找到过期会话", zap.Int("count", len(sessions)))

	// 清理每个过期会话
	for _, session := range sessions {
		// 标记为已删除
		s.db.WithContext(ctx).Model(&entity.CloudUploadSession{}).
			Where("ID = ?", session.ID).
			Update("IS_ACTIVE", "N")

		// 异步清理临时文件
		go s.cleanupChunks(context.Background(), session.ID, session.StoragePath)
	}

	return nil
}

// cleanupChunks 清理临时分片文件
func (s *multipartUploadService) cleanupChunks(ctx context.Context, sessionID uint, storagePath string) {
	logger.Info("清理临时分片文件", zap.Uint("sessionID", sessionID), zap.String("path", storagePath))

	// 1. 列出所有分片文件
	objects, err := s.storage.ListObjects(ctx, storagePath, 0)
	if err != nil {
		logger.Error("列举分片文件失败", zap.Error(err))
		return
	}

	// 2. 删除所有分片文件
	for _, obj := range objects {
		if err := s.storage.Delete(ctx, obj.Key); err != nil {
			logger.Error("删除分片文件失败", zap.String("key", obj.Key), zap.Error(err))
		}
	}

	// 3. 删除分片记录
	if err := s.db.WithContext(ctx).
		Where("SESSION_ID = ?", sessionID).
		Delete(&entity.CloudChunkRecord{}).Error; err != nil {
		logger.Error("删除分片记录失败", zap.Error(err))
	}

	logger.Info("临时文件清理完成", zap.Uint("sessionID", sessionID))
}

// 辅助函数

// calculateMD5 计算数据的MD5
func calculateMD5(data []byte) string {
	hash := md5.Sum(data)
	return hex.EncodeToString(hash[:])
}

// calculateFileMD5 计算文件的MD5
func calculateFileMD5(file *os.File) (string, error) {
	hash := md5.New()
	if _, err := io.Copy(hash, file); err != nil {
		return "", err
	}
	return hex.EncodeToString(hash.Sum(nil)), nil
}

// chunkReader 分片数据读取器
type chunkReader struct {
	data []byte
	pos  int
}

func (r *chunkReader) Read(p []byte) (n int, err error) {
	if r.pos >= len(r.data) {
		return 0, io.EOF
	}
	n = copy(p, r.data[r.pos:])
	r.pos += n
	return n, nil
}

// completeUploadOptimized 完成上传（流式合并优化版本）
// 优化说明：
// 1. 使用 io.Pipe() 创建管道，避免创建本地临时文件
// 2. 使用 goroutine 并发处理：一边读取分片、计算MD5，一边上传到存储
// 3. 减少磁盘 I/O，降低内存占用
// 4. 适用于大文件和多分片场景
func (s *multipartUploadService) completeUploadOptimized(ctx context.Context, session *entity.CloudUploadSession, userID uint) (*entity.CloudFile, error) {
	logger.Info("使用流式合并优化",
		zap.Uint("sessionID", session.ID),
		zap.Int("totalChunks", session.TotalChunks),
		zap.Int64("fileSize", session.FileSize))

	// 1. 检查是否已存在相同MD5的文件（秒传）
	var existingFile entity.CloudFile
	err := s.db.WithContext(ctx).
		Where("MD5 = ? AND OWNER_ID = ? AND IS_ACTIVE = ?", session.FileID, userID, "Y").
		First(&existingFile).Error

	if err == nil {
		// 文件已存在，直接创建新记录（秒传）
		logger.Info("检测到相同文件，使用秒传", zap.String("md5", session.FileID))

		newFile := &entity.CloudFile{
			BaseModel: entity.BaseModel{
				CreateBy: fmt.Sprintf("user_%d", userID),
				UpdateBy: fmt.Sprintf("user_%d", userID),
				IsActive: "Y",
			},
			FileName:    session.FileName,
			FolderID:    session.FolderID,
			StoragePath: existingFile.StoragePath, // 共享存储路径
			FileSize:    session.FileSize,
			FileType:    session.FileType,
			FileExt:     filepath.Ext(session.FileName),
			MD5:         session.FileID,
			OwnerID:     userID,
			StorageType: session.StorageType,
			AccessURL:   existingFile.AccessURL,
		}

		if err := s.db.WithContext(ctx).Create(newFile).Error; err != nil {
			return nil, errors.Wrap(errors.ErrDatabase, "创建文件记录失败（秒传）", err)
		}

		// 更新会话状态
		s.db.WithContext(ctx).Model(&entity.CloudUploadSession{}).
			Where("ID = ?", session.ID).
			Update("STATUS", "completed")

		// 异步清理临时文件
		go s.cleanupChunks(context.Background(), session.ID, session.StoragePath)

		// 更新配额（只增加文件计数，不增加空间使用）
		s.cloudService.UpdateQuota(ctx, userID, 0, 1)

		return newFile, nil
	}

	// 2. 构造最终文件路径
	finalPath := fmt.Sprintf("cloud/%d/%s/%s%s",
		userID,
		time.Now().Format("2006/01/02"),
		uuid.New().String(),
		filepath.Ext(session.FileName))

	// 3. 创建管道 - 核心优化点
	// Reader 端用于存储上传，Writer 端用于写入合并后的数据
	pipeReader, pipeWriter := io.Pipe()

	// 用于收集错误和结果
	type uploadResult struct {
		accessURL string
		err       error
	}
	uploadResultChan := make(chan uploadResult, 1)

	type mergeResult struct {
		actualMD5 string
		err       error
	}
	mergeResultChan := make(chan mergeResult, 1)

	// 4. Goroutine 1: 上传数据到存储（从管道读取）
	go func() {
		defer pipeReader.Close()

		// 直接从管道读取并上传，无需临时文件
		accessURL, err := s.storage.Upload(ctx, finalPath, pipeReader, session.FileType)
		uploadResultChan <- uploadResult{accessURL: accessURL, err: err}
	}()

	// 5. Goroutine 2: 合并分片并写入管道 + 计算MD5
	go func() {
		defer pipeWriter.Close()

		// 创建 MD5 计算器
		hash := md5.New()
		// 使用 MultiWriter 同时写入管道和 MD5 计算器
		multiWriter := io.MultiWriter(pipeWriter, hash)

		// 按顺序读取并合并所有分片
		for i := 0; i < session.TotalChunks; i++ {
			chunkPath := fmt.Sprintf("%s/chunk_%d", session.StoragePath, i)

			// 读取分片
			chunkReader, err := s.storage.Download(ctx, chunkPath)
			if err != nil {
				pipeWriter.CloseWithError(errors.Wrap(errors.ErrInternal, fmt.Sprintf("读取分片 %d 失败", i), err))
				mergeResultChan <- mergeResult{err: err}
				return
			}

			// 流式写入：同时写入管道（用于上传）和 MD5 计算器
			written, err := io.Copy(multiWriter, chunkReader)
			chunkReader.Close()

			if err != nil {
				pipeWriter.CloseWithError(errors.Wrap(errors.ErrInternal, fmt.Sprintf("合并分片 %d 失败", i), err))
				mergeResultChan <- mergeResult{err: err}
				return
			}

			logger.Debug("流式合并分片",
				zap.Int("chunkIndex", i),
				zap.Int64("written", written))
		}

		// 计算最终的 MD5
		actualMD5 := hex.EncodeToString(hash.Sum(nil))
		mergeResultChan <- mergeResult{actualMD5: actualMD5, err: nil}
	}()

	// 6. 等待两个 goroutine 完成
	uploadRes := <-uploadResultChan
	mergeRes := <-mergeResultChan

	// 检查合并错误
	if mergeRes.err != nil {
		logger.Error("流式合并失败", zap.Error(mergeRes.err))
		// 尝试删除可能已部分上传的文件
		s.storage.Delete(ctx, finalPath)
		return nil, mergeRes.err
	}

	// 检查上传错误
	if uploadRes.err != nil {
		logger.Error("流式上传失败", zap.Error(uploadRes.err))
		return nil, errors.Wrap(errors.ErrInternal, "上传最终文件失败", uploadRes.err)
	}

	// 7. 验证文件完整性（MD5）
	if mergeRes.actualMD5 != session.FileID {
		logger.Error("文件MD5校验失败",
			zap.String("expected", session.FileID),
			zap.String("actual", mergeRes.actualMD5))
		// 删除已上传的错误文件
		s.storage.Delete(ctx, finalPath)
		return nil, errors.New(errors.ErrInvalidParam, "文件MD5校验失败")
	}

	logger.Info("文件MD5校验成功（流式合并）", zap.String("md5", mergeRes.actualMD5))

	// 8. 创建文件记录
	file := &entity.CloudFile{
		BaseModel: entity.BaseModel{
			CreateBy: fmt.Sprintf("user_%d", userID),
			UpdateBy: fmt.Sprintf("user_%d", userID),
			IsActive: "Y",
		},
		FileName:    session.FileName,
		FolderID:    session.FolderID,
		StoragePath: finalPath,
		FileSize:    session.FileSize,
		FileType:    session.FileType,
		FileExt:     filepath.Ext(session.FileName),
		MD5:         session.FileID,
		OwnerID:     userID,
		StorageType: session.StorageType,
		AccessURL:   uploadRes.accessURL,
	}

	if err := s.db.WithContext(ctx).Create(file).Error; err != nil {
		// 删除已上传的文件
		s.storage.Delete(ctx, finalPath)
		return nil, errors.Wrap(errors.ErrDatabase, "创建文件记录失败", err)
	}

	// 9. 更新配额
	s.cloudService.UpdateQuota(ctx, userID, session.FileSize, 1)

	// 10. 更新会话状态为已完成
	s.db.WithContext(ctx).Model(&entity.CloudUploadSession{}).
		Where("ID = ?", session.ID).
		Update("STATUS", "completed")

	// 11. 异步清理临时文件
	go s.cleanupChunks(context.Background(), session.ID, session.StoragePath)

	logger.Info("文件上传完成（流式合并）",
		zap.Uint("fileID", file.ID),
		zap.String("fileName", file.FileName),
		zap.Int64("fileSize", file.FileSize))

	return file, nil
}
